{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "images_dir = \"../Resources/train/NORMAL/\"\n",
    "train_path = \"../Resources/train/NORMAL/\"\n",
    "\n",
    "Image.open(images_dir + \"IM-0115-0001.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 464, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, shutil\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Image folder\n",
    "images_dir\n",
    "WIDTH = 1858//4\n",
    "LENGTH = 2090//4\n",
    "CHANNELS = 3\n",
    "\n",
    "dim = (WIDTH, LENGTH)\n",
    "\n",
    "# Resizing all the images to same dimension\n",
    "X_image_train = []\n",
    "for fname in listdir(images_dir):\n",
    "    fpath = os.path.join(images_dir, fname)\n",
    "    im = Image.open(fpath)\n",
    "    im_resized = im.resize(dim)\n",
    "    X_image_train.append(im_resized)\n",
    "\n",
    "## Converting the image to numpy array\n",
    "X_image_array=[]\n",
    "for x in range(len(X_image_train)):\n",
    "    X_image=np.array(X_image_train[x],dtype='uint8')\n",
    "    img2 = cv2.merge((X_image,X_image,X_image))\n",
    "    X_image_array.append(img2)\n",
    "\n",
    "# Checking the size of a single image\n",
    "X_image_array[15].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_image_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1341, 522, 464, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor = np.stack(X_image_array)\n",
    "final_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_tensor = final_tensor.reshape(1341, LENGTH, WIDTH, CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_gen = ImageDataGenerator(rotation_range = 20,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              rescale=1/255,\n",
    "                              featurewise_center = True,\n",
    "                              shear_range=0.1,\n",
    "                              zoom_range=.1,\n",
    "                              horizontal_flip=True,\n",
    "                              fill_mode=\"nearest\")\n",
    "\n",
    "image_gen.fit(final_tensor)\n",
    "del final_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4929 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../Resources/train/\"\n",
    "test_path = \"../Resources/val/\"\n",
    "batch_size=8\n",
    "image_shape = (WIDTH, LENGTH, CHANNELS)\n",
    "\n",
    "\n",
    "\n",
    "train_image_gen = image_gen.flow_from_directory(train_path,\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode=\"binary\")\n",
    "\n",
    "test_image_gen = image_gen.flow_from_directory(test_path,\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode=\"binary\",\n",
    "                                              shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORMAL': 0, 'PNEUMONIA': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15165451658845838267,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 16229677608512480614\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 5753587537827171161\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11338085172\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 6087616996711810473\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizer import Adam\n",
    "\n",
    "model= Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=96, kernel_size=(12,12), strides=(4,4), input_shape=image_shape, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "          \n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "          \n",
    "model.add(Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "          \n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "          \n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "    \n",
    "model.add(Dense(2096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "          \n",
    "model.add(Dense(2096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "          \n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "adam = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 114, 128, 96)      41568     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 114, 128, 96)      384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 56, 63, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 63, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 63, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 31, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 27, 31, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 27, 31, 384)       147840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 27, 31, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 27, 31, 256)       98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 27, 31, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 49920)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2096)              104634416 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2096)              4395312   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2097      \n",
      "=================================================================\n",
      "Total params: 110,825,073\n",
      "Trainable params: 110,822,321\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 617 steps, validate for 2 steps\n",
      "Epoch 1/20\n",
      "617/617 [==============================] - 306s 495ms/step - loss: 2.5415 - accuracy: 0.8328 - val_loss: 38.8627 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "249/617 [===========>..................] - ETA: 2:59 - loss: 0.5361 - accuracy: 0.8635"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "results = model.fit_generator(train_image_gen, epochs=20,\n",
    "                             validation_data=test_image_gen,\n",
    "                             callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_image_gen)\n",
    "\n",
    "predictions = pred>0.5\n",
    "\n",
    "predictions\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_image_gen.classes\n",
    "\n",
    "print(train_image_gen.class_indices)\n",
    "print(\"\\n\")\n",
    "print(classification_report(test_image_gen.classes,predictions))\n",
    "\n",
    "print(confusion_matrix(test_image_gen.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
